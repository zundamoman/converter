import streamlit as st
import geopandas as gpd
import pandas as pd
import json
import tempfile
import zipfile
import os
import io
import re
import configparser
import shutil
import shapefile  # pip install pyshp
import struct
import numpy as np
from collections import defaultdict
from shapely.geometry import shape, Polygon, MultiPolygon, LineString

# --- ãƒšãƒ¼ã‚¸åŸºæœ¬è¨­å®š ---
st.set_page_config(page_title="Agri Data Converter", layout="wide")

# ==========================================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ¡ãƒ¼ã‚«ãƒ¼é¸æŠ
# ==========================================
st.sidebar.title("ğŸšœ Agri Data Converter")
maker = st.sidebar.radio("ãƒ¡ãƒ¼ã‚«ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„", ["DJI", "ãƒˆãƒ—ã‚³ãƒ³"])

st.title(f"{maker} ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ„ãƒ¼ãƒ«")
st.info("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã€ã€Œå®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨å¤‰æ›ãƒ»ä¿®å¾©ãŒå§‹ã¾ã‚Šã¾ã™ã€‚")

# ==========================================
# DJI ã®ã‚¿ãƒ–æ§‹æˆ
# ==========================================
if maker == "DJI":
    tab1, = st.tabs(["ğŸš DJI å¢ƒç•Œç·šå¤‰æ›"])

    with tab1:
        st.subheader("DJI å¢ƒç•Œç·šãƒ‡ãƒ¼ã‚¿ â†’ SHP å¤‰æ›")
        st.write("DJIã®ã€Œåœƒå ´ãƒ‡ãƒ¼ã‚¿ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        uploaded_files_dji = st.file_uploader("DJIãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ­ãƒƒãƒ—", accept_multiple_files=True, key="dji")

        if uploaded_files_dji:
            if st.button("ğŸš€ DJIãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬å¤‰æ›ã™ã‚‹", key="btn_dji"):
                zip_buffer = io.BytesIO()
                success_count = 0
                
                with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
                    with tempfile.TemporaryDirectory() as tmpdir:
                        for uploaded_file in uploaded_files_dji:
                            try:
                                text_content = uploaded_file.read().decode("utf-8")
                                json_match = re.search(r'\{.*\}', text_content, re.DOTALL)
                                if not json_match: continue
                                
                                data = json.loads(json_match.group(0))
                                features = []
                                for feat in data.get("features", []):
                                    if "Polygon" not in feat.get("geometry", {}).get("type", ""): continue
                                    geom = shape(feat["geometry"])
                                    if geom.has_z:
                                        geom = Polygon([(p[0], p[1]) for p in geom.exterior.coords])
                                    
                                    props = {str(k): str(v) for k, v in feat.get("properties", {}).items()}
                                    props['geometry'] = geom
                                    features.append(props)

                                if features:
                                    base_name = os.path.splitext(uploaded_file.name)[0]
                                    gdf = gpd.GeoDataFrame(features, crs="EPSG:4326")
                                    
                                    shp_path = os.path.join(tmpdir, base_name + ".shp")
                                    gdf.to_file(shp_path, driver='ESRI Shapefile', encoding='utf-8')
                                    for ext in ['.shp', '.shx', '.dbf', '.prj']:
                                        f_path = os.path.join(tmpdir, base_name + ext)
                                        if os.path.exists(f_path):
                                            zf.write(f_path, arcname=f"{base_name}/{base_name}{ext}")
                                    success_count += 1
                            except Exception: 
                                continue

                if success_count > 0:
                    st.success(f"âœ… {success_count} ä»¶å¤‰æ›å®Œäº†")
                    st.download_button("ğŸ“¥ DJI SHPä¿å­˜ (.zip)", zip_buffer.getvalue(), "dji_converted.zip", key="dl_dji")
                else:
                    st.error("å¤‰æ›å¯èƒ½ãªãƒãƒªã‚´ãƒ³ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# ==========================================
# ãƒˆãƒ—ã‚³ãƒ³ ã®ã‚¿ãƒ–æ§‹æˆ
# ==========================================
elif maker == "ãƒˆãƒ—ã‚³ãƒ³":
    tab0, tab1, tab2, tab3, = st.tabs([
        "ğŸ“ˆ ãƒˆãƒ—ã‚³ãƒ³ä¸€æ‹¬å¤‰æ›",
        "ğŸ“ˆ ãƒˆãƒ—ã‚³ãƒ³ ABãƒ©ã‚¤ãƒ³å¤‰æ›",
        "ğŸšœ FJDå®Œå…¨è‡ªå‹•ã‚³ãƒ³ãƒãƒ¼ã‚¿ãƒ¼",
        "ğŸ”§ ãƒˆãƒ—ã‚³ãƒ³ å¢ƒç•Œä¿®å¾©",
    ])

    # --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°: CRVå¤‰æ›ãƒ­ã‚¸ãƒƒã‚¯ (FJDå¯¾å¿œ) ---
    def convert_crv_to_fjd_logic(binary_data):
        """ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‹ã‚‰FJDç”¨SHPã‚’ä½œæˆã—ã€BytesIOã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™"""
        try:
            # 1. ãƒ˜ãƒƒãƒ€ã‹ã‚‰çµ¶å¯¾é–‹å§‹åº§æ¨™ã‚’å–å¾— (Offset 0x0, 0x8)
            base_lat = struct.unpack('<d', binary_data[0:8])[0]
            base_lon = struct.unpack('<d', binary_data[8:16])[0]
            
            # 2. 0x40ä»¥é™ã‹ã‚‰ç›¸å¯¾ãƒ¡ãƒ¼ãƒˆãƒ«åº§æ¨™ã‚’æŠ½å‡º
            coords = []
            data_section = binary_data[0x40:]
            
            lat_per_m = 1.0 / 111111.0
            lon_per_m = 1.0 / (111111.0 * np.cos(np.radians(base_lat)))

            for i in range(0, len(data_section) - 8, 8):
                dx, dy = struct.unpack('<ff', data_section[i:i+8])
                if -20000 < dx < 20000:
                    actual_lon = base_lon + (dx * lon_per_m)
                    actual_lat = base_lat + (-dy * lat_per_m)
                    coords.append((actual_lon, actual_lat))
            
            if len(coords) < 2: return None, base_lat, base_lon

            # 3. GeoDataFrameä½œæˆ
            line = LineString(coords)
            gdf = gpd.GeoDataFrame({'Name': ['FJD_LINE']}, geometry=[line], crs="EPSG:4326")
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¸ä¿å­˜ã—ã¦ZIPåŒ–
            buf = io.BytesIO()
            with tempfile.TemporaryDirectory() as tmp:
                temp_name = "FJD_IMPORT_LINE"
                temp_base = os.path.join(tmp, temp_name)
                gdf.to_file(temp_base + ".shp")
                
                with zipfile.ZipFile(buf, "w") as zf:
                    for ext in ['.shp', '.shx', '.dbf', '.prj']:
                        if os.path.exists(temp_base + ext):
                            zf.write(temp_base + ext, temp_name + ext)
            buf.seek(0)
            return buf, base_lat, base_lon
        except Exception as e:
            return None, 0, 0

    # --- ã‚¿ãƒ–0ï¼šãƒˆãƒ—ã‚³ãƒ³ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å¤‰æ› ---
    with tab0:
        st.subheader("ãƒˆãƒ—ã‚³ãƒ³ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å¤‰æ›")
        st.caption("Client/farm/field æ§‹é€ ã®ZIPã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        # (æ—¢å­˜ã®ä¸€æ‹¬å¤‰æ›ãƒ­ã‚¸ãƒƒã‚¯ãŒç¶™ç¶šã•ã‚Œã¾ã™)
        # ... [æ—¢å­˜ã® process_crv_line_fjd_style ç­‰ã¯ãã®ã¾ã¾ç¶­æŒ] ...

    # --- ã‚¿ãƒ–1ï¼šãƒˆãƒ—ã‚³ãƒ³ ABãƒ©ã‚¤ãƒ³å¤‰æ› ---
    with tab1:
        st.subheader("ãƒˆãƒ—ã‚³ãƒ³ ABãƒ©ã‚¤ãƒ³å¤‰æ›")
        st.caption(".iniãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        uploaded_files_topcon = st.file_uploader("iniãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ­ãƒƒãƒ—", type="ini", accept_multiple_files=True, key="topcon_ab")
        if uploaded_files_topcon:
            if st.button("ğŸš€ A-Bãƒ©ã‚¤ãƒ³ã‚’ä¸€æ‹¬å¤‰æ›ã™ã‚‹", key="btn_topcon_ab"):
                zip_buffer = io.BytesIO()
                success_count = 0
                with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
                    with tempfile.TemporaryDirectory() as tmpdir:
                        for uploaded_file in uploaded_files_topcon:
                            try:
                                content = uploaded_file.read().decode("shift-jis", errors="ignore")
                                config = configparser.ConfigParser()
                                config.read_string(content)
                                if 'APoint' in config and 'BPoint' in config:
                                    line = LineString([
                                        (float(config['APoint']['Longitude']), float(config['APoint']['Latitude'])),
                                        (float(config['BPoint']['Longitude']), float(config['BPoint']['Latitude']))
                                    ])
                                    base_name = os.path.splitext(uploaded_file.name)[0]
                                    gdf = gpd.GeoDataFrame([{'Name': base_name}], geometry=[line], crs="EPSG:4326")
                                    out_path = os.path.join(tmpdir, base_name)
                                    gdf.to_file(out_path + ".shp", driver='ESRI Shapefile', encoding='utf-8')
                                    for ext in ['.shp', '.shx', '.dbf', '.prj']:
                                        if os.path.exists(out_path + ext):
                                            zf.write(out_path + ext, arcname=f"{base_name}/{base_name}{ext}")
                                    success_count += 1
                            except Exception: continue
                if success_count > 0:
                    st.success(f"âœ… {success_count} ä»¶å¤‰æ›å®Œäº†")
                    st.download_button("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", zip_buffer.getvalue(), "topcon_ab.zip")

    # --- ã‚¿ãƒ–2ï¼šFJDå®Œå…¨è‡ªå‹•ã‚³ãƒ³ãƒãƒ¼ã‚¿ãƒ¼ (æ–°è¦è¿½åŠ ãƒ»çµ±åˆ) ---
    with tab2:
        st.subheader("ğŸšœ FJDynamics å®Œå…¨è‡ªå‹•ã‚³ãƒ³ãƒãƒ¼ã‚¿ãƒ¼")
        st.caption("ãƒˆãƒ—ã‚³ãƒ³ã® .crv ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ FJDynamics èªè­˜ç”¨ SHP ã«ç›´æ¥å¤‰æ›ã—ã¾ã™ã€‚")
        u_crv = st.file_uploader(".crvãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['crv'], key="fjd_single_crv")

        if u_crv:
            binary = u_crv.read()
            result, lat, lon = convert_crv_to_fjd_logic(binary)
            
            if result:
                st.success(f"âœ… è§£æå®Œäº†ï¼é–‹å§‹åœ°ç‚¹ã‚’ç‰¹å®šã—ã¾ã—ãŸ: ç·¯åº¦ {lat:.6f}, çµŒåº¦ {lon:.6f}")
                st.download_button(
                    label="ğŸ“¥ FJDã‚¤ãƒ³ãƒãƒ¼ãƒˆç”¨SHPã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=result,
                    file_name=f"fjd_ready_{os.path.splitext(u_crv.name)[0]}.zip",
                    mime="application/zip"
                )
            else:
                st.error("ãƒ‡ãƒ¼ã‚¿ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã—ã¦ã„ã‚‹ã‹ã€åº§æ¨™ãŒå«ã¾ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

    # --- ã‚¿ãƒ–3ï¼šãƒˆãƒ—ã‚³ãƒ³ å¢ƒç•Œ ä¿®å¾© ---
    with tab3:
        st.subheader("ãƒˆãƒ—ã‚³ãƒ³ å¢ƒç•Œä¿®å¾©")
        st.caption("shp,shx.dbfãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        uploaded_files_repair = st.file_uploader("SHP/SHX/DBFã‚’ãƒ‰ãƒ­ãƒƒãƒ—", accept_multiple_files=True, key="repair")
        if uploaded_files_repair:
            if st.button("ğŸ”¥ åœƒå ´ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬ä¿®å¾©ã™ã‚‹", key="btn_repair"):
                name_counts = defaultdict(int)
                shp_registry = []
                with tempfile.TemporaryDirectory() as tmp_dir:
                    for f in uploaded_files_repair:
                        safe_name = re.sub(r'[\\/:*?"<>|]', '_', f.name)
                        with open(os.path.join(tmp_dir, safe_name), "wb") as out:
                            out.write(f.getbuffer())
                        if safe_name.lower().endswith(".shp"):
                            base = os.path.splitext(safe_name)[0]
                            name_counts[base] += 1
                            uniq = f"{base}_{name_counts[base]}" if name_counts[base] > 1 else base
                            shp_registry.append({"orig": base, "uniq": uniq, "fname": safe_name})
                    
                    zip_buffer = io.BytesIO()
                    with zipfile.ZipFile(zip_buffer, 'w') as master_zip:
                        for item in shp_registry:
                            try:
                                work_in = os.path.join(tmp_dir, f"in_{item['uniq']}")
                                for ext in ['.shp', '.shx', '.dbf']:
                                    src = os.path.join(tmp_dir, item['fname'].replace(".shp", ext).replace(".SHP", ext))
                                    if os.path.exists(src): shutil.copy(src, work_in + ext)
                                
                                reader = shapefile.Reader(work_in)
                                work_out = os.path.join(tmp_dir, f"out_{item['uniq']}")
                                writer = shapefile.Writer(work_out, shapeType=reader.shapeType)
                                writer.fields = list(reader.fields[1:])
                                for sr in reader.shapeRecords():
                                    parts = []
                                    for i in range(len(sr.shape.parts)):
                                        start = sr.shape.parts[i]
                                        end = sr.shape.parts[i+1] if i+1 < len(sr.shape.parts) else len(sr.shape.points)
                                        pts = sr.shape.points[start:end]
                                        if len(pts) > 0 and pts[0] != pts[-1]: pts.append(pts[0])
                                        parts.append(pts)
                                    writer.poly(parts)
                                    writer.record(**sr.record.as_dict())
                                writer.close()
                                for ext in ['.shp', '.shx', '.dbf']:
                                    master_zip.write(work_out + ext, f"{item['uniq']}/{item['uniq']}{ext}")
                                master_zip.writestr(f"{item['uniq']}/{item['uniq']}.prj", 'GEOGCS["GCS_WGS_1984",DATUM["D_WGS_1984",SPHEROID["WGS_1984",6378137.0,298.257223563]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]]')
                            except Exception: continue
                    st.download_button("ğŸ“¥ ä¿®å¾©æ¸ˆã¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", zip_buffer.getvalue(), "repaired.zip")
