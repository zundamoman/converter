import streamlit as st
import geopandas as gpd
import pandas as pd
import json
import tempfile
import zipfile
import os
import io
import re
import configparser
import shutil
import shapefile  # pip install pyshp
import struct
import numpy as np
from collections import defaultdict
from shapely.geometry import shape, Polygon, MultiPolygon, LineString

# --- ãƒšãƒ¼ã‚¸åŸºæœ¬è¨­å®š ---
st.set_page_config(page_title="Agri Data Converter", layout="wide")

# ==========================================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒ¡ãƒ‹ãƒ¥ãƒ¼æ§‹æˆ
# ==========================================
st.sidebar.title("ğŸšœ Agri Data Converter")

# å¤§é …ç›®ã®é¸æŠ
category = st.sidebar.radio("ãƒ¡ãƒ¼ã‚«ãƒ¼ãƒ»ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ", ["DJI", "ãƒˆãƒ—ã‚³ãƒ³"])

# å°é …ç›®ã®é¸æŠ
if category == "DJI":
    menu = st.sidebar.selectbox(
        "æ©Ÿèƒ½ã‚’é¸æŠ", 
        ["DJI å¢ƒç•Œç·šãƒ‡ãƒ¼ã‚¿ â†’ SHP å¤‰æ›"]
    )
else:
    menu = st.sidebar.selectbox(
        "æ©Ÿèƒ½ã‚’é¸æŠ", 
        [
            "ãƒˆãƒ—ã‚³ãƒ³ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å¤‰æ› (ç›´ç·šãƒ»æ›²ç·šãƒ»å¢ƒç•Œ)",
            "ãƒˆãƒ—ã‚³ãƒ³ A-Bãƒ©ã‚¤ãƒ³å¤‰æ›",
            "SHPä¸€æ‹¬ä¿®å¾©",
            "ãƒˆãƒ—ã‚³ãƒ³ãƒ‡ãƒ¼ã‚¿ã¾ã¨ã‚ã¦å¤‰æ›"
        ]
    )

st.title(f"{menu}")
st.info("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã€ã€Œå®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨å¤‰æ›ãƒ»ä¿®å¾©ãŒå§‹ã¾ã‚Šã¾ã™ã€‚")

# ==========================================
# å„æ©Ÿèƒ½ã®ãƒ­ã‚¸ãƒƒã‚¯
# ==========================================

# --- 1. DJI å¢ƒç•Œç·šãƒ‡ãƒ¼ã‚¿ â†’ SHP å¤‰æ› ---
if menu == "DJI å¢ƒç•Œç·šãƒ‡ãƒ¼ã‚¿ â†’ SHP å¤‰æ›":
    st.subheader("DJIã®ã€Œåœƒå ´ãƒ‡ãƒ¼ã‚¿ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    uploaded_files_dji = st.file_uploader("DJIãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ­ãƒƒãƒ—", accept_multiple_files=True, key="dji")

    if uploaded_files_dji:
        if st.button("ğŸš€ DJIãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬å¤‰æ›ã™ã‚‹", key="btn_dji"):
            zip_buffer = io.BytesIO()
            success_count = 0
            
            with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
                with tempfile.TemporaryDirectory() as tmpdir:
                    for uploaded_file in uploaded_files_dji:
                        try:
                            text_content = uploaded_file.read().decode("utf-8")
                            json_match = re.search(r'\{.*\}', text_content, re.DOTALL)
                            if not json_match: continue
                            
                            data = json.loads(json_match.group(0))
                            features = []
                            for feat in data.get("features", []):
                                if "Polygon" not in feat.get("geometry", {}).get("type", ""): continue
                                geom = shape(feat["geometry"])
                                if geom.has_z:
                                    geom = Polygon([(p[0], p[1]) for p in geom.exterior.coords])
                                
                                props = {str(k): str(v) for k, v in feat.get("properties", {}).items()}
                                props['geometry'] = geom
                                features.append(props)

                            if features:
                                base_name = os.path.splitext(uploaded_file.name)[0]
                                gdf = gpd.GeoDataFrame(features, crs="EPSG:4326")
                                
                                shp_path = os.path.join(tmpdir, base_name + ".shp")
                                gdf.to_file(shp_path, driver='ESRI Shapefile', encoding='utf-8')
                                for ext in ['.shp', '.shx', '.dbf', '.prj']:
                                    f_path = os.path.join(tmpdir, base_name + ext)
                                    if os.path.exists(f_path):
                                        zf.write(f_path, arcname=f"{base_name}/{base_name}{ext}")
                                success_count += 1
                        except Exception: 
                            continue

            if success_count > 0:
                st.success(f"âœ… {success_count} ä»¶å¤‰æ›å®Œäº†")
                st.download_button("ğŸ“¥ DJI SHPä¿å­˜ (.zip)", zip_buffer.getvalue(), "dji_converted.zip", key="dl_dji")
            else:
                st.error("å¤‰æ›å¯èƒ½ãªãƒãƒªã‚´ãƒ³ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# --- 2. ãƒˆãƒ—ã‚³ãƒ³ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å¤‰æ› (ç›´ç·šãƒ»æ›²ç·šãƒ»å¢ƒç•Œ) ---
elif menu == "ãƒˆãƒ—ã‚³ãƒ³ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å¤‰æ› (ç›´ç·šãƒ»æ›²ç·šãƒ»å¢ƒç•Œ)":
    st.subheader("ãƒˆãƒ—ã‚³ãƒ³ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å¤‰æ› (ç›´ç·šãƒ»æ›²ç·šãƒ»å¢ƒç•Œ)")
    st.caption("client/farm/fieldã®ä¸­ã«ABLines / Boundaries / Curves ãƒ•ã‚©ãƒ«ãƒ€ã‚’å«ã‚€ZIPã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

    def process_crv_line(field_root, curves_dir):
        for root, dirs, files in os.walk(curves_dir):
            for f in files:
                if f.lower().endswith(".crv"):
                    crv_path = os.path.join(root, f)
                    base_name = os.path.splitext(f)[0]
                    try:
                        with open(crv_path, 'rb') as fb:
                            binary_data = fb.read()
                        if len(binary_data) < 0x48: continue
                        base_lat = struct.unpack('<d', binary_data[0:8])[0]
                        base_lon = struct.unpack('<d', binary_data[8:16])[0]
                        coords = []
                        data_section = binary_data[0x40:]
                        lat_per_m = 1.0 / 111111.0
                        lon_per_m = 1.0 / (111111.0 * np.cos(np.radians(base_lat)))
                        for i in range(0, len(data_section) - 8, 8):
                            dx, dy = struct.unpack('<ff', data_section[i:i+8])
                            if -20000 < dx < 20000:
                                actual_lon = base_lon + (dx * lon_per_m)
                                actual_lat = base_lat + (-dy * lat_per_m)
                                coords.append((actual_lon, actual_lat))
                        if len(coords) >= 2:
                            line = LineString(coords)
                            gdf = gpd.GeoDataFrame([{'Name': base_name, 'geometry': line}], crs="EPSG:4326")
                            gdf.to_file(os.path.join(field_root, f"{base_name}.shp"), driver='ESRI Shapefile', encoding='utf-8')
                    except Exception as e:
                        st.error(f"âŒ Curveså¤‰æ›å¤±æ•—: {f} - {e}")

    def process_ab_line_v2(field_root, ablines_dir):
        for root, dirs, files in os.walk(ablines_dir):
            for f in files:
                if f.lower().endswith(".ini"):
                    ini_path = os.path.join(root, f)
                    base_name = os.path.splitext(f)[0]
                    try:
                        config = configparser.ConfigParser()
                        with open(ini_path, 'rb') as fb:
                            raw_data = fb.read()
                        content = None
                        for enc in ['utf-8', 'utf-16', 'shift-jis']:
                            try:
                                content = raw_data.decode(enc); break
                            except: continue
                        if content:
                            config.read_string(content)
                            if 'APoint' in config and 'BPoint' in config:
                                lat_a, lon_a = float(config['APoint']['Latitude']), float(config['APoint']['Longitude'])
                                lat_b, lon_b = float(config['BPoint']['Latitude']), float(config['BPoint']['Longitude'])
                                line = LineString([(lon_a, lat_a), (lon_b, lat_b)])
                                gdf = gpd.GeoDataFrame([{'Name': base_name, 'geometry': line}], crs="EPSG:4326")
                                gdf.to_file(os.path.join(field_root, f"{base_name}.shp"), driver='ESRI Shapefile', encoding='utf-8')
                    except Exception as e:
                        st.error(f"âŒ ABãƒ©ã‚¤ãƒ³å¤‰æ›å¤±æ•—: {f} - {e}")

    def process_boundary_v2(shp_path, output_dir):
        base_name = os.path.splitext(os.path.basename(shp_path))[0]
        output_base = os.path.join(output_dir, base_name)
        prj_data = 'GEOGCS["GCS_WGS_1984",DATUM["D_WGS_1984",SPHEROID["WGS_1984",6378137.0,298.257223563]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]]'
        try:
            reader = shapefile.Reader(os.path.splitext(shp_path)[0])
            writer = shapefile.Writer(output_base, shapeType=reader.shapeType)
            writer.fields = list(reader.fields[1:])
            for i, shape_rec in enumerate(reader.shapeRecords()):
                geom = shape_rec.shape
                new_parts = []
                for pi in range(len(geom.parts)):
                    si, ei = geom.parts[pi], (geom.parts[pi+1] if pi+1 < len(geom.parts) else len(geom.points))
                    pts = geom.points[si:ei]
                    if pts and pts[0] != pts[-1]: pts.append(pts[0])
                    new_parts.append(pts)
                writer.poly(new_parts)
                rec = shape_rec.record.as_dict()
                rec.update({'id': str(i+1), 'Name': base_name, 'visibility': 1, 'altitudeMo': "clampToGround"})
                writer.record(**rec)
            writer.close()
            with open(output_base + ".prj", "w") as f: f.write(prj_data)
        except Exception as e:
            st.error(f"âŒ å¢ƒç•Œä¿®å¾©å¤±æ•—: {base_name} - {e}")

    uploaded_zip_tab5 = st.file_uploader("ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="zip", key="topcon_v2")

    if uploaded_zip_tab5:
        if st.button("å¤‰æ›ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’é–‹å§‹", key="btn_v2"):
            with tempfile.TemporaryDirectory() as tmp_dir:
                extract_path = os.path.join(tmp_dir, "extracted")
                with zipfile.ZipFile(uploaded_zip_tab5, 'r') as z:
                    z.extractall(extract_path)

                for root, dirs, files in os.walk(extract_path, topdown=False):
                    if any(d in dirs for d in ["ABLines", "Boundaries", "Curves"]):
                        temp_save = os.path.join(tmp_dir, "temp_shp_v2")
                        if os.path.exists(temp_save): shutil.rmtree(temp_save)
                        os.makedirs(temp_save)

                        ab_dir = os.path.join(root, "ABLines")
                        if os.path.exists(ab_dir): process_ab_line_v2(temp_save, ab_dir)
                        
                        bound_dir = os.path.join(root, "Boundaries")
                        if os.path.exists(bound_dir):
                            for f in os.listdir(bound_dir):
                                if f.lower().endswith(".shp"):
                                    process_boundary_v2(os.path.join(bound_dir, f), temp_save)

                        curves_dir = os.path.join(root, "Curves")
                        if os.path.exists(curves_dir): process_crv_line(temp_save, curves_dir)

                        for entry in os.listdir(root):
                            entry_path = os.path.join(root, entry)
                            if os.path.isdir(entry_path): shutil.rmtree(entry_path)
                            else: os.remove(entry_path)

                        for item in os.listdir(temp_save):
                            shutil.move(os.path.join(temp_save, item), root)
                        
                        shutil.rmtree(temp_save)

                final_zip_name = os.path.join(tmp_dir, "final_output_v2")
                shutil.make_archive(final_zip_name, 'zip', extract_path)
                with open(final_zip_name + ".zip", "rb") as f:
                    st.success("âœ… å¤‰æ›å®Œäº†ï¼ABLines, Boundaries, Curvesã™ã¹ã¦ãŒSHPã«çµ±åˆã•ã‚Œã¾ã—ãŸã€‚")
                    st.download_button("ğŸ“¥ å¤‰æ›æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", f, file_name="topcon_v2_converted.zip")

# --- 3. ãƒˆãƒ—ã‚³ãƒ³ A-Bãƒ©ã‚¤ãƒ³å¤‰æ› ---
elif menu == "ãƒˆãƒ—ã‚³ãƒ³ A-Bãƒ©ã‚¤ãƒ³å¤‰æ›":
    st.subheader("ãƒˆãƒ—ã‚³ãƒ³ã® `.ini` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    uploaded_files_topcon = st.file_uploader("iniãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ­ãƒƒãƒ—", type="ini", accept_multiple_files=True, key="topcon_ab")

    if uploaded_files_topcon:
        if st.button("ğŸš€ A-Bãƒ©ã‚¤ãƒ³ã‚’ä¸€æ‹¬å¤‰æ›ã™ã‚‹", key="btn_topcon_ab"):
            zip_buffer = io.BytesIO()
            success_count = 0
            with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
                with tempfile.TemporaryDirectory() as tmpdir:
                    for uploaded_file in uploaded_files_topcon:
                        try:
                            content = uploaded_file.read().decode("shift-jis", errors="ignore")
                            config = configparser.ConfigParser()
                            config.read_string(content)
                            if 'APoint' in config and 'BPoint' in config:
                                line = LineString([
                                    (float(config['APoint']['Longitude']), float(config['APoint']['Latitude'])),
                                    (float(config['BPoint']['Longitude']), float(config['BPoint']['Latitude']))
                                ])
                                base_name = os.path.splitext(uploaded_file.name)[0]
                                gdf = gpd.GeoDataFrame([{'Name': base_name, 'geometry': line}], crs="EPSG:4326")
                                out_path = os.path.join(tmpdir, base_name)
                                gdf.to_file(out_path + ".shp", driver='ESRI Shapefile', encoding='utf-8')
                                for ext in ['.shp', '.shx', '.dbf', '.prj']:
                                    if os.path.exists(out_path + ext):
                                        zf.write(out_path + ext, arcname=f"{base_name}/{base_name}{ext}")
                                success_count += 1
                        except Exception: continue
            if success_count > 0:
                st.success(f"âœ… {success_count} ä»¶å¤‰æ›å®Œäº†")
                st.download_button("ğŸ“¥ ãƒˆãƒ—ã‚³ãƒ³ SHPä¿å­˜ (.zip)", zip_buffer.getvalue(), "topcon_ab_converted.zip")
            else:
                st.error("æœ‰åŠ¹ãª A-B ãƒ©ã‚¤ãƒ³æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# --- 4. SHPä¸€æ‹¬ä¿®å¾© ---
elif menu == "SHPä¸€æ‹¬ä¿®å¾©":
    st.subheader("ä¸æ•´åˆãªSHPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰©ç†ä¿®å¾©ã—ã¾ã™ã€‚")
    uploaded_files_repair = st.file_uploader("SHP/SHX/DBFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã¾ã¨ã‚ã¦ãƒ‰ãƒ­ãƒƒãƒ—", accept_multiple_files=True, key="repair")

    if uploaded_files_repair:
        if st.button("ğŸ”¥ åœƒå ´ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬ä¿®å¾©ã™ã‚‹", key="btn_repair"):
            name_counts = defaultdict(int)
            shp_registry = []
            with tempfile.TemporaryDirectory() as tmp_dir:
                for f in uploaded_files_repair:
                    safe_name = re.sub(r'[\\/:*?"<>|]', '_', f.name)
                    with open(os.path.join(tmp_dir, safe_name), "wb") as out:
                        out.write(f.getbuffer())
                    if safe_name.lower().endswith(".shp"):
                        base = os.path.splitext(safe_name)[0]
                        name_counts[base] += 1
                        uniq = f"{base}_{name_counts[base]}" if name_counts[base] > 1 else base
                        shp_registry.append({"orig": base, "uniq": uniq, "fname": safe_name})

                zip_buffer = io.BytesIO()
                success_count = 0
                with zipfile.ZipFile(zip_buffer, 'w') as master_zip:
                    for item in shp_registry:
                        try:
                            work_in = os.path.join(tmp_dir, f"in_{item['uniq']}")
                            for ext in ['.shp', '.shx', '.dbf']:
                                src = os.path.join(tmp_dir, item['fname'].replace(".shp", ext).replace(".SHP", ext))
                                if os.path.exists(src): shutil.copy(src, work_in + ext)
                            reader = shapefile.Reader(work_in)
                            work_out = os.path.join(tmp_dir, f"out_{item['uniq']}")
                            writer = shapefile.Writer(work_out, shapeType=reader.shapeType)
                            writer.fields = list(reader.fields[1:])
                            for sr in reader.shapeRecords():
                                parts = []
                                for i in range(len(sr.shape.parts)):
                                    start = sr.shape.parts[i]
                                    end = sr.shape.parts[i+1] if i+1 < len(sr.shape.parts) else len(sr.shape.points)
                                    pts = sr.shape.points[start:end]
                                    if len(pts) > 0 and pts[0] != pts[-1]: pts.append(pts[0])
                                    parts.append(pts)
                                writer.poly(parts)
                                writer.record(**sr.record.as_dict())
                            writer.close()
                            reader.close()
                            for ext in ['.shp', '.shx', '.dbf']:
                                master_zip.write(work_out + ext, f"{item['uniq']}/{item['uniq']}{ext}")
                            master_zip.writestr(f"{item['uniq']}/{item['uniq']}.prj", 'GEOGCS["GCS_WGS_1984",DATUM["D_WGS_1984",SPHEROID["WGS_1984",6378137.0,298.257223563]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]]')
                            success_count += 1
                        except Exception: continue
                if success_count > 0:
                    st.success(f"âœ… {success_count} ä»¶ä¿®å¾©å®Œäº†")
                    st.download_button("ğŸ“¥ ä¿®å¾©æ¸ˆã¿ã‚’ä¿å­˜", zip_buffer.getvalue(), "repaired.zip")

# --- 5. ãƒˆãƒ—ã‚³ãƒ³ãƒ‡ãƒ¼ã‚¿ã¾ã¨ã‚ã¦å¤‰æ› ---
elif menu == "ãƒˆãƒ—ã‚³ãƒ³ãƒ‡ãƒ¼ã‚¿ã¾ã¨ã‚ã¦å¤‰æ›":
    st.subheader("ãƒˆãƒ—ã‚³ãƒ³ãƒ‡ãƒ¼ã‚¿ã¾ã¨ã‚ã¦å¤‰æ›")
    st.caption("cliet/farm/field(.zip)")

    def sub_process_ab_line(field_root, ablines_dir):
        for root, dirs, files in os.walk(ablines_dir):
            for f in files:
                if f.lower().endswith(".ini"):
                    ini_path = os.path.join(root, f)
                    base_name = os.path.splitext(f)[0]
                    try:
                        config = configparser.ConfigParser()
                        with open(ini_path, 'rb') as fb:
                            raw_data = fb.read()
                        content = None
                        for enc in ['utf-8', 'utf-16', 'shift-jis']:
                            try:
                                content = raw_data.decode(enc); break
                            except: continue
                        if content:
                            config.read_string(content)
                            if 'APoint' in config and 'BPoint' in config:
                                lat_a, lon_a = float(config['APoint']['Latitude']), float(config['APoint']['Longitude'])
                                lat_b, lon_b = float(config['BPoint']['Latitude']), float(config['BPoint']['Longitude'])
                                line = LineString([(lon_a, lat_a), (lon_b, lat_b)])
                                gdf = gpd.GeoDataFrame([{'Name': base_name, 'geometry': line}], crs="EPSG:4326")
                                gdf.to_file(os.path.join(field_root, f"{base_name}.shp"), driver='ESRI Shapefile', encoding='utf-8')
                    except Exception as e:
                        st.error(f"âŒ ABãƒ©ã‚¤ãƒ³å¤‰æ›å¤±æ•—: {f} - {e}")

    def sub_process_boundary(shp_path, output_dir):
        base_name = os.path.splitext(os.path.basename(shp_path))[0]
        output_base = os.path.join(output_dir, base_name)
        prj_data = 'GEOGCS["GCS_WGS_1984",DATUM["D_WGS_1984",SPHEROID["WGS_1984",6378137.0,298.257223563]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]]'
        try:
            reader = shapefile.Reader(os.path.splitext(shp_path)[0])
            writer = shapefile.Writer(output_base, shapeType=reader.shapeType)
            writer.fields = list(reader.fields[1:])
            for i, shape_rec in enumerate(reader.shapeRecords()):
                geom = shape_rec.shape
                new_parts = []
                for pi in range(len(geom.parts)):
                    si, ei = geom.parts[pi], (geom.parts[pi+1] if pi+1 < len(geom.parts) else len(geom.points))
                    pts = geom.points[si:ei]
                    if pts and pts[0] != pts[-1]: pts.append(pts[0])
                    new_parts.append(pts)
                writer.poly(new_parts)
                rec = shape_rec.record.as_dict()
                rec.update({'id': str(i+1), 'Name': base_name, 'visibility': 1, 'altitudeMo': "clampToGround"})
                writer.record(**rec)
            writer.close()
            with open(output_base + ".prj", "w") as f: f.write(prj_data)
        except Exception as e:
            st.error(f"âŒ å¢ƒç•Œä¿®å¾©å¤±æ•—: {base_name} - {e}")

    uploaded_zip_topcon_all = st.file_uploader("ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="zip", key="topcon_all")

    if uploaded_zip_topcon_all:
        if st.button("å¤‰æ›ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’é–‹å§‹", key="btn_topcon_all"):
            with tempfile.TemporaryDirectory() as tmp_dir:
                extract_path = os.path.join(tmp_dir, "extracted")
                with zipfile.ZipFile(uploaded_zip_topcon_all, 'r') as z:
                    z.extractall(extract_path)
                for root, dirs, files in os.walk(extract_path, topdown=False):
                    if "ABLines" in dirs or "Boundaries" in dirs:
                        temp_save = os.path.join(tmp_dir, "temp_shp_only")
                        if os.path.exists(temp_save): shutil.rmtree(temp_save)
                        os.makedirs(temp_save)
                        ab_dir = os.path.join(root, "ABLines")
                        if os.path.exists(ab_dir): sub_process_ab_line(temp_save, ab_dir)
                        bound_dir = os.path.join(root, "Boundaries")
                        if os.path.exists(bound_dir):
                            for f in os.listdir(bound_dir):
                                if f.lower().endswith(".shp"):
                                    sub_process_boundary(os.path.join(bound_dir, f), temp_save)
                        for entry in os.listdir(root):
                            entry_path = os.path.join(root, entry)
                            if os.path.isdir(entry_path): shutil.rmtree(entry_path)
                            else: os.remove(entry_path)
                        for item in os.listdir(temp_save):
                            shutil.move(os.path.join(temp_save, item), root)
                        shutil.rmtree(temp_save)
                final_zip_name = os.path.join(tmp_dir, "final_output")
                shutil.make_archive(final_zip_name, 'zip', extract_path)
                with open(final_zip_name + ".zip", "rb") as f:
                    st.success("âœ… å¤‰æ›å®Œäº†ï¼ä¸è¦ãªãƒ•ã‚©ãƒ«ãƒ€ã¯å‰Šé™¤ã•ã‚Œã¾ã—ãŸã€‚")
                    st.download_button("ğŸ“¥ å¤‰æ›æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", f, file_name="topcon_clean.zip")
