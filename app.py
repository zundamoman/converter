import streamlit as st
import geopandas as gpd
import pandas as pd
import json
import tempfile
import zipfile
import os
import io
import re
import configparser
import shutil
import shapefile  # pip install pyshp
import struct
import numpy as np
from collections import defaultdict
from shapely.geometry import shape, Polygon, MultiPolygon, LineString

# --- ãƒšãƒ¼ã‚¸åŸºæœ¬è¨­å®š ---
st.set_page_config(page_title="Agri Data Converter", layout="wide")

# ==========================================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ¡ãƒ¼ã‚«ãƒ¼é¸æŠ
# ==========================================
st.sidebar.title("ğŸšœ Agri Data Converter")
maker = st.sidebar.radio("ãƒ¡ãƒ¼ã‚«ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„", ["DJI", "ãƒˆãƒ—ã‚³ãƒ³"])

st.title(f"{maker} ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ„ãƒ¼ãƒ«")
st.info("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã€ã€Œå¤‰æ›é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨å¤‰æ›ãƒ»ä¿®å¾©ãŒå§‹ã¾ã‚Šã¾ã™ã€‚")

# ==========================================
# DJI ã®ã‚¿ãƒ–æ§‹æˆ
# ==========================================
if maker == "DJI":
    tab1, = st.tabs(["ğŸš DJI å¢ƒç•Œç·šå¤‰æ›"])

    with tab1:
        st.subheader("DJI å¢ƒç•Œç·šãƒ‡ãƒ¼ã‚¿ â†’ SHP å¤‰æ›")
        st.write("DJIã®ã€Œåœƒå ´ãƒ‡ãƒ¼ã‚¿ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        uploaded_files_dji = st.file_uploader("DJIãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ­ãƒƒãƒ—", accept_multiple_files=True, key="dji")

        if uploaded_files_dji:
            if st.button("ğŸš€ å¤‰æ›é–‹å§‹", key="btn_dji"):
                zip_buffer = io.BytesIO()
                success_count = 0
                
                with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
                    with tempfile.TemporaryDirectory() as tmpdir:
                        for uploaded_file in uploaded_files_dji:
                            try:
                                text_content = uploaded_file.read().decode("utf-8")
                                json_match = re.search(r'\{.*\}', text_content, re.DOTALL)
                                if not json_match: continue
                                
                                data = json.loads(json_match.group(0))
                                features = []
                                for feat in data.get("features", []):
                                    if "Polygon" not in feat.get("geometry", {}).get("type", ""): continue
                                    geom = shape(feat["geometry"])
                                    if geom.has_z:
                                        geom = Polygon([(p[0], p[1]) for p in geom.exterior.coords])
                                    
                                    props = {str(k): str(v) for k, v in feat.get("properties", {}).items()}
                                    props['geometry'] = geom
                                    features.append(props)

                                if features:
                                    base_name = os.path.splitext(uploaded_file.name)[0]
                                    gdf = gpd.GeoDataFrame(features, crs="EPSG:4326")
                                    
                                    shp_path = os.path.join(tmpdir, base_name + ".shp")
                                    gdf.to_file(shp_path, driver='ESRI Shapefile', encoding='utf-8')
                                    for ext in ['.shp', '.shx', '.dbf', '.prj']:
                                        f_path = os.path.join(tmpdir, base_name + ext)
                                        if os.path.exists(f_path):
                                            zf.write(f_path, arcname=f"{base_name}/{base_name}{ext}")
                                    success_count += 1
                            except Exception: 
                                continue

                if success_count > 0:
                    st.success(f"âœ… {success_count} ä»¶ã®å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                    st.download_button("ğŸ“¥ å¤‰æ›ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰(.zip)", zip_buffer.getvalue(), "dji_converted.zip", key="dl_dji")
                else:
                    st.error("å¤‰æ›å¯èƒ½ãªãƒãƒªã‚´ãƒ³ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# ==========================================
# ãƒˆãƒ—ã‚³ãƒ³ ã®ã‚¿ãƒ–æ§‹æˆ
# ==========================================
elif maker == "ãƒˆãƒ—ã‚³ãƒ³":
    tab0, tab1, tab2, tab3, = st.tabs([
        "ğŸš€ ãƒˆãƒ—ã‚³ãƒ³ä¸€æ‹¬å¤‰æ›",
        "ğŸ“ˆ ãƒˆãƒ—ã‚³ãƒ³ ABãƒ©ã‚¤ãƒ³å¤‰æ›",
        "ğŸ“ˆ ãƒˆãƒ—ã‚³ãƒ³ æ›²ç·šå¤‰æ›",
        "ğŸ”§ ãƒˆãƒ—ã‚³ãƒ³ å¢ƒç•Œä¿®å¾©",
    ])

    # --- ã‚¿ãƒ–0ï¼šãƒˆãƒ—ã‚³ãƒ³ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å¤‰æ› (åç§°ç¶­æŒç‰ˆ) ---
    with tab0:
        st.subheader("ãƒˆãƒ—ã‚³ãƒ³ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬å¤‰æ› (ãƒ©ã‚¤ãƒ³ãƒ»å¢ƒç•Œãƒ»æ›²ç·šã™ã¹ã¦)")
        st.caption("ABLines / Boundaries / Curves ãƒ•ã‚©ãƒ«ãƒ€ã‚’å«ã‚€ZIPã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚å…ƒãƒ•ã‚¡ã‚¤ãƒ«åã‚’ãã®ã¾ã¾å¼•ãç¶™ãã¾ã™ã€‚")

        def process_crv_line_fjd_style(field_root, curves_dir):
            """Curveså†…ã®.crvã¨åŒã˜åå‰ã§SHPã‚’å‡ºåŠ›"""
            for root, dirs, files in os.walk(curves_dir):
                for f in files:
                    if f.lower().endswith(".crv"):
                        crv_path = os.path.join(root, f)
                        base_name = os.path.splitext(f)[0]
                        try:
                            with open(crv_path, 'rb') as fb:
                                binary_data = fb.read()
                            if len(binary_data) < 0x48: continue
                            
                            base_lat = struct.unpack('<d', binary_data[0:8])[0]
                            base_lon = struct.unpack('<d', binary_data[8:16])[0]
                            coords = []
                            data_section = binary_data[0x40:]
                            lat_per_m = 1.0 / 111111.0
                            lon_per_m = 1.0 / (111111.0 * np.cos(np.radians(base_lat)))

                            for i in range(0, len(data_section) - 8, 8):
                                dx, dy = struct.unpack('<ff', data_section[i:i+8])
                                if -20000 < dx < 20000:
                                    actual_lon = base_lon + (dx * lon_per_m)
                                    actual_lat = base_lat + (-dy * lat_per_m)
                                    coords.append((actual_lon, actual_lat))

                            if len(coords) >= 2:
                                line = LineString(coords)
                                gdf = gpd.GeoDataFrame([{'Name': base_name, 'geometry': line}], crs="EPSG:4326")
                                gdf.to_file(os.path.join(field_root, f"{base_name}.shp"), driver='ESRI Shapefile', encoding='utf-8')
                        except Exception: continue

        def process_ab_line_v2(field_root, ablines_dir):
            """ABãƒ©ã‚¤ãƒ³ã®.iniã¨åŒã˜åå‰ã§SHPã‚’å‡ºåŠ›"""
            for root, dirs, files in os.walk(ablines_dir):
                for f in files:
                    if f.lower().endswith(".ini"):
                        ini_path = os.path.join(root, f)
                        base_name = os.path.splitext(f)[0]
                        try:
                            config = configparser.ConfigParser()
                            with open(ini_path, 'rb') as fb:
                                raw_data = fb.read()
                            content = None
                            for enc in ['utf-8', 'utf-16', 'shift-jis']:
                                try: content = raw_data.decode(enc); break
                                except: continue
                            if content:
                                config.read_string(content)
                                p1 = config['APoint'] if 'APoint' in config else config['Point1'] if 'Point1' in config else None
                                p2 = config['BPoint'] if 'BPoint' in config else config['Point2'] if 'Point2' in config else None
                                if p1 and p2:
                                    line = LineString([(float(p1['Longitude']), float(p1['Latitude'])), (float(p2['Longitude']), float(p2['Latitude']))])
                                    gdf = gpd.GeoDataFrame([{'Name': base_name, 'geometry': line}], crs="EPSG:4326")
                                    gdf.to_file(os.path.join(field_root, f"{base_name}.shp"), driver='ESRI Shapefile', encoding='utf-8')
                        except Exception: continue

        def process_boundary_v2(shp_path, output_dir):
            """å¢ƒç•ŒSHPã‚’ä¿®å¾©ã—ã€å…ƒã®åå‰ã‚’ç¶­æŒã—ã¦å‡ºåŠ›"""
            base_name = os.path.splitext(os.path.basename(shp_path))[0]
            output_base = os.path.join(output_dir, base_name)
            prj_data = 'GEOGCS["GCS_WGS_1984",DATUM["D_WGS_1984",SPHEROID["WGS_1984",6378137.0,298.257223563]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]]'
            try:
                reader = shapefile.Reader(os.path.splitext(shp_path)[0])
                writer = shapefile.Writer(output_base, shapeType=reader.shapeType)
                writer.fields = list(reader.fields[1:])
                for sr in reader.shapeRecords():
                    geom = sr.shape
                    new_parts = []
                    for pi in range(len(geom.parts)):
                        si, ei = geom.parts[pi], (geom.parts[pi+1] if pi+1 < len(geom.parts) else len(geom.points))
                        pts = geom.points[si:ei]
                        if pts and pts[0] != pts[-1]: pts.append(pts[0])
                        new_parts.append(pts)
                    writer.poly(new_parts)
                    rec = sr.record.as_dict()
                    rec.update({'id': str(sr.record[0]), 'Name': base_name})
                    writer.record(**rec)
                writer.close()
                with open(output_base + ".prj", "w") as f: f.write(prj_data)
            except Exception: continue

        uploaded_zip_topcon_v2 = st.file_uploader("ä¸€æ‹¬å¤‰æ›ç”¨ZIPã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="zip", key="topcon_v2")

        if uploaded_zip_topcon_v2:
            if st.button("ğŸš€ å¤‰æ›é–‹å§‹", key="btn_v2"):
                with tempfile.TemporaryDirectory() as tmp_dir:
                    extract_path = os.path.join(tmp_dir, "extracted")
                    with zipfile.ZipFile(uploaded_zip_topcon_v2, 'r') as z:
                        z.extractall(extract_path)

                    for root, dirs, files in os.walk(extract_path, topdown=False):
                        dirs_lower = [d.lower() for d in dirs]
                        if any(x in dirs_lower for x in ["ablines", "boundaries", "curves"]):
                            
                            # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã”ã¨ã«æˆæœç‰©ã‚’ä¸€æ™‚ä¿å­˜ã™ã‚‹å ´æ‰€ï¼ˆä¸Šæ›¸ãé˜²æ­¢ï¼‰
                            field_temp = os.path.join(tmp_dir, "current_field_out")
                            if os.path.exists(field_temp): shutil.rmtree(field_temp)
                            os.makedirs(field_temp)

                            dir_map = {d.lower(): d for d in dirs}

                            # 1. ç›´ç·š (ABLines)
                            if "ablines" in dir_map:
                                process_ab_line_v2(field_temp, os.path.join(root, dir_map["ablines"]))
                            
                            # 2. å¢ƒç•Œ (Boundaries)
                            if "boundaries" in dir_map:
                                b_dir = os.path.join(root, dir_map["boundaries"])
                                for f in os.listdir(b_dir):
                                    if f.lower().endswith(".shp"):
                                        process_boundary_v2(os.path.join(b_dir, f), field_temp)

                            # 3. æ›²ç·š (Curves)
                            if "curves" in dir_map:
                                process_crv_line_fjd_style(field_temp, os.path.join(root, dir_map["curves"]))

                            # æ—¢å­˜ãƒ•ã‚©ãƒ«ãƒ€ã¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¶ˆå»
                            for d in dirs: shutil.rmtree(os.path.join(root, d))
                            for f in files: os.remove(os.path.join(root, f))

                            # æˆæœç‰©ã‚’ç§»å‹•
                            if os.path.exists(field_temp):
                                for item in os.listdir(field_temp):
                                    shutil.move(os.path.join(field_temp, item), root)

                    final_zip_name = os.path.join(tmp_dir, "final_output_v2")
                    shutil.make_archive(final_zip_name, 'zip', extract_path)
                    with open(final_zip_name + ".zip", "rb") as f:
                        st.success("âœ… å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸã€‚å…ƒãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç¶­æŒã—ã¦ã„ã¾ã™ã€‚")
                        st.download_button("ğŸ“¥ å¤‰æ›ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰(.zip)", f, file_name="topcon_integrated_fixed.zip")

    # --- ã‚¿ãƒ–1ï¼šãƒˆãƒ—ã‚³ãƒ³ ABãƒ©ã‚¤ãƒ³å¤‰æ› (å˜ä½“) ---
    with tab1:
        st.subheader("ãƒˆãƒ—ã‚³ãƒ³ ABãƒ©ã‚¤ãƒ³å¤‰æ› (å˜ä½“ãƒ•ã‚¡ã‚¤ãƒ«ç”¨)")
        uploaded_files_topcon = st.file_uploader("iniãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ­ãƒƒãƒ—", type="ini", accept_multiple_files=True, key="topcon_ab_single")
        if uploaded_files_topcon:
            if st.button("ğŸš€ å¤‰æ›é–‹å§‹", key="btn_topcon_ab_single"):
                zip_buffer = io.BytesIO()
                success_count = 0
                with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
                    with tempfile.TemporaryDirectory() as tmpdir:
                        for uploaded_file in uploaded_files_topcon:
                            try:
                                content = uploaded_file.read().decode("shift-jis", errors="ignore")
                                config = configparser.ConfigParser()
                                config.read_string(content)
                                p1 = config['APoint'] if 'APoint' in config else config['Point1'] if 'Point1' in config else None
                                p2 = config['BPoint'] if 'BPoint' in config else config['Point2'] if 'Point2' in config else None
                                if p1 and p2:
                                    line = LineString([(float(p1['Longitude']), float(p1['Latitude'])), (float(p2['Longitude']), float(p2['Latitude']))])
                                    base_name = os.path.splitext(uploaded_file.name)[0]
                                    gdf = gpd.GeoDataFrame([{'Name': base_name, 'geometry': line}], crs="EPSG:4326")
                                    out_path = os.path.join(tmpdir, base_name)
                                    gdf.to_file(out_path + ".shp", driver='ESRI Shapefile', encoding='utf-8')
                                    for ext in ['.shp', '.shx', '.dbf', '.prj']:
                                        if os.path.exists(out_path + ext):
                                            zf.write(out_path + ext, arcname=f"{base_name}/{base_name}{ext}")
                                    success_count += 1
                            except Exception: continue
                if success_count > 0:
                    st.success(f"âœ… {success_count}ä»¶ã®å¤‰æ›å®Œäº†ã€‚")
                    st.download_button("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", zip_buffer.getvalue(), "topcon_abline.zip")

    # --- ã‚¿ãƒ–2ï¼šãƒˆãƒ—ã‚³ãƒ³ æ›²ç·šå¤‰æ› (å˜ä½“) ---
    with tab2:
        st.subheader("ãƒˆãƒ—ã‚³ãƒ³ æ›²ç·šå¤‰æ› (å˜ä½“ãƒ•ã‚¡ã‚¤ãƒ«ç”¨)")
        u_crv_single = st.file_uploader(".crvãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['crv'], key="fjd_single")
        if u_crv_single:
            if st.button("ğŸš€ å¤‰æ›é–‹å§‹", key="btn_crv_single"):
                binary = u_crv_single.read()
                # å…±é€šãƒ­ã‚¸ãƒƒã‚¯åˆ©ç”¨
                try:
                    base_lat = struct.unpack('<d', binary[0:8])[0]
                    base_lon = struct.unpack('<d', binary[8:16])[0]
                    coords = []
                    data_section = binary[0x40:]
                    lat_per_m = 1.0 / 111111.0
                    lon_per_m = 1.0 / (111111.0 * np.cos(np.radians(base_lat)))
                    for i in range(0, len(data_section) - 8, 8):
                        dx, dy = struct.unpack('<ff', data_section[i:i+8])
                        if -20000 < dx < 20000:
                            coords.append((base_lon + (dx * lon_per_m), base_lat + (-dy * lat_per_m)))
                    
                    if len(coords) >= 2:
                        base_name = os.path.splitext(u_crv_single.name)[0]
                        line = LineString(coords)
                        gdf = gpd.GeoDataFrame({'Name': [base_name]}, geometry=[line], crs="EPSG:4326")
                        
                        buf = io.BytesIO()
                        with tempfile.TemporaryDirectory() as td:
                            temp_base = os.path.join(td, base_name)
                            gdf.to_file(temp_base + ".shp")
                            with zipfile.ZipFile(buf, "w") as zf:
                                for ext in ['.shp', '.shx', '.dbf', '.prj']:
                                    if os.path.exists(temp_base + ext):
                                        zf.write(temp_base + ext, base_name + ext)
                        buf.seek(0)
                        st.success(f"âœ… å¤‰æ›æˆåŠŸ: {base_name}")
                        st.download_button("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", buf, file_name=f"{base_name}.zip")
                except Exception:
                    st.error("å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    # --- ã‚¿ãƒ–3ï¼šãƒˆãƒ—ã‚³ãƒ³ å¢ƒç•Œ ä¿®å¾© (å˜ä½“) ---
    with tab3:
        st.subheader("ãƒˆãƒ—ã‚³ãƒ³ å¢ƒç•Œä¿®å¾©")
        uploaded_files_repair = st.file_uploader("SHP/SHX/DBFã‚’ãƒ‰ãƒ­ãƒƒãƒ—", accept_multiple_files=True, key="repair_v3")
        if uploaded_files_repair:
            if st.button("ğŸš€ å¤‰æ›é–‹å§‹", key="btn_repair_v3"):
                name_counts = defaultdict(int)
                shp_registry = []
                with tempfile.TemporaryDirectory() as tmp_dir:
                    for f in uploaded_files_repair:
                        safe_name = re.sub(r'[\\/:*?"<>|]', '_', f.name)
                        with open(os.path.join(tmp_dir, safe_name), "wb") as out:
                            out.write(f.getbuffer())
                        if safe_name.lower().endswith(".shp"):
                            base = os.path.splitext(safe_name)[0]
                            name_counts[base] += 1
                            uniq = f"{base}_{name_counts[base]}" if name_counts[base] > 1 else base
                            shp_registry.append({"orig": base, "uniq": uniq, "fname": safe_name})
                    
                    zip_buffer = io.BytesIO()
                    with zipfile.ZipFile(zip_buffer, 'w') as master_zip:
                        for item in shp_registry:
                            try:
                                work_in = os.path.join(tmp_dir, f"in_{item['uniq']}")
                                for ext in ['.shp', '.shx', '.dbf']:
                                    src = os.path.join(tmp_dir, item['fname'].replace(".shp", ext).replace(".SHP", ext))
                                    if os.path.exists(src): shutil.copy(src, work_in + ext)
                                
                                reader = shapefile.Reader(work_in)
                                work_out = os.path.join(tmp_dir, f"out_{item['uniq']}")
                                writer = shapefile.Writer(work_out, shapeType=reader.shapeType)
                                writer.fields = list(reader.fields[1:])
                                for sr in reader.shapeRecords():
                                    geom = sr.shape
                                    new_parts = []
                                    for pi in range(len(geom.parts)):
                                        si, ei = geom.parts[pi], (geom.parts[pi+1] if pi+1 < len(geom.parts) else len(geom.points))
                                        pts = geom.points[si:ei]
                                        if pts and pts[0] != pts[-1]: pts.append(pts[0])
                                        new_parts.append(pts)
                                    writer.poly(new_parts)
                                    writer.record(**sr.record.as_dict())
                                writer.close()
                                for ext in ['.shp', '.shx', '.dbf']:
                                    master_zip.write(work_out + ext, f"{item['uniq']}/{item['uniq']}{ext}")
                                master_zip.writestr(f"{item['uniq']}/{item['uniq']}.prj", 'GEOGCS["GCS_WGS_1984",DATUM["D_WGS_1984",SPHEROID["WGS_1984",6378137.0,298.257223563]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]]')
                            except Exception: continue
                    
                    st.success("âœ… ä¿®å¾©ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                    st.download_button("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰(.zip)", zip_buffer.getvalue(), "repaired_topcon.zip")
